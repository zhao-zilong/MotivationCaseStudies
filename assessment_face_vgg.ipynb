{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1337)\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import clone_model\n",
    "from models import get_model, resnet_v1, resnet_v2\n",
    "from util import select_clean_uncertain, combine_result, inject_noise\n",
    "import time\n",
    "import argparse\n",
    "from util import other_class\n",
    "from tensorflow.python.lib.io import file_io\n",
    "from keras.utils import np_utils, multi_gpu_model\n",
    "from keras import backend as K\n",
    "from loss_acc_plot import loss_acc_plot\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "# from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"\" if no GPU\n",
    "os.environ['PYTHONHASHSEED'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = {'mnist': 10, 'svhn': 10, 'cifar-10': 10, 'cifar-100': 100, 'celeb': 20}\n",
    "dataset = \"celeb\"\n",
    "noise_ratio = 0\n",
    "data_ratio = 100\n",
    "repeat = 1\n",
    "# X_train, y_train, X_test, y_test, un_selected_index = get_data('celeb', init_noise_ratio, data_ratio, random_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_data, test_labels):\n",
    "    predictions = model.predict(test_data)\n",
    "    #print(predictions)\n",
    "    #predictions = list(np.around(np.array(predictions),0))\n",
    "    predictions_ = np.argmax(predictions, axis = 1)\n",
    "    predictions_test = np.argmax(test_labels, axis = 1)\n",
    "    \n",
    "    accuracy = accuracy_score(predictions_test, predictions_)\n",
    "    #print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(noise_ratio):\n",
    "    X_train = np.load('data/image_train_20.npy')\n",
    "    X_test = np.load('data/image_test_20.npy')\n",
    "    y_train = np.load('data/label_train_20.npy')\n",
    "    y_test = np.load('data/label_test_20.npy')\n",
    "\n",
    "    image_shape = 128\n",
    "    X_train = X_train.reshape(-1, image_shape, image_shape, 3)\n",
    "    X_test = X_test.reshape(-1, image_shape, image_shape, 3)\n",
    "\n",
    "    X_train = X_train / 255.0\n",
    "    X_test = X_test / 255.0\n",
    "\n",
    "    means = X_train.mean(axis=0)\n",
    "    X_train = (X_train - means)  # / std\n",
    "    X_test = (X_test - means)  # / std\n",
    "\n",
    "    # they are 2D originally in cifar\n",
    "    y_train = y_train.ravel()\n",
    "    y_test = y_test.ravel()\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    if noise_ratio > 0:\n",
    "            n_samples = y_train.shape[0]\n",
    "            n_noisy = int(noise_ratio*n_samples/100)\n",
    "            np.random.seed()\n",
    "            noisy_idx = np.random.choice(n_samples, n_noisy, replace=False)\n",
    "            for i in noisy_idx:\n",
    "                y_train[i] = other_class(n_classes=NUM_CLASSES[dataset], current_class=y_train[i])\n",
    "    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    y_train = np_utils.to_categorical(y_train, NUM_CLASSES[dataset])\n",
    "    y_test = np_utils.to_categorical(y_test, NUM_CLASSES[dataset])\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for re in range(repeat):\n",
    "    result_list = []\n",
    "    for noise_ratio in [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]:          \n",
    "        X_train, X_test, y_train, y_test = get_data(noise_ratio)    \n",
    "        image_shape = X_train.shape[1:]\n",
    "        model_quality = get_model(dataset, input_tensor=None, input_shape=image_shape, num_classes=NUM_CLASSES[dataset])\n",
    "    \n",
    "        optimizer = SGD(lr=0.01, decay=1e-4, momentum=0.9)\n",
    "        model_quality.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy']) \n",
    "        epochs_init = 100\n",
    "        batch_size = 128\n",
    "\n",
    "        h_quality  =  model_quality.fit(X_train, y_train,\n",
    "                            steps_per_epoch=X_train.shape[0]//batch_size, epochs=epochs_init, shuffle=False,\n",
    "                            validation_data=(X_test, y_test)\n",
    "                            )\n",
    "        result_list.append(h_quality.history['val_accuracy'][-1])\n",
    "    print(\"result_list: \",result_list)\n",
    "    final_result_list.append(result_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
